{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Score-based Diffusion on MNIST \u2014 From Scratch in PyTorch (VP/DDPM)\n", "\n", "We train a noise-conditional score model on MNIST via **denoising score matching** in the DDPM/VP formulation."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1) Setup"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import os, math, time\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "from torch.utils.data import DataLoader\n", "import torchvision\n", "from torchvision import datasets, transforms, utils as vutils\n", "import matplotlib.pyplot as plt\n", "\n", "torch.manual_seed(0); np.random.seed(0)\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "print(\"device:\", device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2) Hyperparameters"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["img_size   = 28\n", "in_ch      = 1\n", "T          = 300\n", "beta_start = 1e-4\n", "beta_end   = 0.02\n", "batch_size = 128\n", "epochs     = 10\n", "lr         = 2e-4\n", "sample_every = 1\n", "out_dir = \"mnist_diffusion_outputs\"\n", "os.makedirs(out_dir, exist_ok=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3) Data loading (MNIST)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["transform = transforms.Compose([\n", "    transforms.ToTensor(),\n", "    transforms.Normalize((0.5,), (0.5,))\n", "])\n", "train_data = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n", "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n", "\n", "x_real = next(iter(train_loader))[0][:64]\n", "grid = vutils.make_grid(x_real, nrow=8, normalize=True, value_range=(-1,1))\n", "plt.figure(figsize=(6,6)); plt.axis(\"off\"); plt.title(\"Real MNIST (normalized)\")\n", "plt.imshow(np.transpose(grid.cpu().numpy(), (1,2,0))); plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4) Diffusion utilities (betas, alphas)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["betas = torch.linspace(beta_start, beta_end, T, dtype=torch.float32, device=device)\n", "alphas = 1.0 - betas\n", "alphas_bar = torch.cumprod(alphas, dim=0)\n", "\n", "def extract(a, t, x_shape):\n", "    out = a.gather(-1, t).float()\n", "    return out.view(-1, *((1,)*(len(x_shape)-1)))\n", "\n", "@torch.no_grad()\n", "def q_sample(x0, t, noise=None):\n", "    if noise is None:\n", "        noise = torch.randn_like(x0)\n", "    sqrt_ab = extract(torch.sqrt(alphas_bar), t, x0.shape)\n", "    sqrt_mab = extract(torch.sqrt(1.0 - alphas_bar), t, x0.shape)\n", "    return sqrt_ab * x0 + sqrt_mab * noise, noise"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5) Time embedding"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["class TimeEmbedding(nn.Module):\n", "    def __init__(self, dim, max_period=10000):\n", "        super().__init__()\n", "        self.dim = dim\n", "        self.mlp = nn.Sequential(\n", "            nn.Linear(dim, dim*4), nn.SiLU(),\n", "            nn.Linear(dim*4, dim*4), nn.SiLU(),\n", "            nn.Linear(dim*4, dim),\n", "        )\n", "        self.max_period = max_period\n", "    def forward(self, t):\n", "        half = self.dim // 2\n", "        freqs = torch.exp(-math.log(self.max_period) * torch.arange(0, half, device=t.device).float() / half)\n", "        args = t.float().unsqueeze(1) * freqs.unsqueeze(0) * 2*math.pi / T\n", "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n", "        if self.dim % 2 == 1:\n", "            emb = F.pad(emb, (0,1))\n", "        return self.mlp(emb)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6) Model \u2014 small U-Net-ish predictor"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def conv_block(in_c, out_c, time_dim):\n", "    return nn.ModuleDict({\n", "        \"conv\": nn.Sequential(\n", "            nn.Conv2d(in_c, out_c, 3, padding=1), nn.GroupNorm(8, out_c), nn.SiLU(),\n", "            nn.Conv2d(out_c, out_c, 3, padding=1), nn.GroupNorm(8, out_c), nn.SiLU(),\n", "        ),\n", "        \"time\": nn.Sequential(nn.SiLU(), nn.Linear(time_dim, out_c))\n", "    })\n", "\n", "class UNetMini(nn.Module):\n", "    def __init__(self, in_ch=1, base=64, time_dim=128):\n", "        super().__init__()\n", "        self.time_mlp = TimeEmbedding(time_dim)\n", "        self.in_conv = nn.Conv2d(in_ch, base, 3, padding=1)\n", "        self.down1 = conv_block(base, base*2, time_dim); self.pool = nn.AvgPool2d(2)\n", "        self.down2 = conv_block(base*2, base*4, time_dim)\n", "        self.mid   = conv_block(base*4, base*4, time_dim)\n", "        self.up1_t = nn.ConvTranspose2d(base*4, base*2, 2, 2)\n", "        self.up1   = conv_block(base*4, base*2, time_dim)\n", "        self.up2_t = nn.ConvTranspose2d(base*2, base, 2, 2)\n", "        self.up2   = conv_block(base*2, base, time_dim)\n", "        self.out_conv = nn.Conv2d(base, in_ch, 3, padding=1)\n", "    def _apply(self, block, h, t_emb):\n", "        temb = block[\"time\"](t_emb)[:, :, None, None]\n", "        h = block[\"conv\"](h) + temb\n", "        return h\n", "    def forward(self, x, t):\n", "        t_emb = self.time_mlp(t)\n", "        h0 = self.in_conv(x)\n", "        h1 = self._apply(self.down1, self.pool(h0), t_emb)\n", "        h2 = self._apply(self.down2, self.pool(h1), t_emb)\n", "        hm = self._apply(self.mid, h2, t_emb)\n", "        u1 = self.up1_t(hm); u1 = torch.cat([u1, h1], dim=1); u1 = self._apply(self.up1, u1, t_emb)\n", "        u2 = self.up2_t(u1); u2 = torch.cat([u2, h0], dim=1); u2 = self._apply(self.up2, u2, t_emb)\n", "        return self.out_conv(u2)\n", "\n", "model = UNetMini(in_ch=1, base=64, time_dim=128).to(device)\n", "print(\"Params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7) Loss & optimizer (denoising MSE)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["opt = optim.AdamW(model.parameters(), lr=lr)\n", "\n", "def diffusion_loss(x0):\n", "    B = x0.size(0)\n", "    t = torch.randint(0, T, (B,), device=x0.device).long()\n", "    x_t, noise = q_sample(x0, t)\n", "    eps_pred = model(x_t, t)\n", "    return F.mse_loss(eps_pred, noise)\n", "\n", "with torch.no_grad():\n", "    xb = next(iter(train_loader))[0][:8].to(device)\n", "    tb = torch.randint(0, T, (xb.size(0),), device=device)\n", "    xt, eps = q_sample(xb, tb)\n", "    grid = vutils.make_grid(torch.cat([xb, xt], dim=0), nrow=8, normalize=True, value_range=(-1,1))\n", "    plt.figure(figsize=(8,4)); plt.axis(\"off\"); plt.title(\"x0 (top) vs x_t (bottom)\")\n", "    plt.imshow(np.transpose(grid.cpu().numpy(), (1,2,0))); plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8) Sampling (ancestral DDPM)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["@torch.no_grad()\n", "def p_sample_loop(n=64):\n", "    x = torch.randn(n, in_ch, img_size, img_size, device=device)\n", "    for t_step in reversed(range(T)):\n", "        t = torch.full((n,), t_step, device=device, dtype=torch.long)\n", "        eps_theta = model(x, t)\n", "        beta_t   = extract(betas, t, x.shape)\n", "        alpha_t  = extract(alphas, t, x.shape)\n", "        ab_t     = extract(alphas_bar, t, x.shape)\n", "        mean = (1/torch.sqrt(alpha_t)) * (x - (beta_t/torch.sqrt(1 - ab_t)) * eps_theta)\n", "        if t_step > 0:\n", "            beta_tilde = beta_t * (1 - extract(alphas_bar, t-1, x.shape)) / (1 - ab_t)\n", "            x = mean + torch.sqrt(beta_tilde) * torch.randn_like(x)\n", "        else:\n", "            x = mean\n", "    return x.clamp(-1,1)\n", "\n", "samp = p_sample_loop(64).cpu()\n", "grid = vutils.make_grid(samp, nrow=8, normalize=True, value_range=(-1,1))\n", "plt.figure(figsize=(6,6)); plt.axis(\"off\"); plt.title(\"Sample (untrained model)\")\n", "plt.imshow(np.transpose(grid.numpy(), (1,2,0))); plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9) Training loop"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["log = []\n", "for ep in range(1, epochs+1):\n", "    t0 = time.time()\n", "    for x,_ in train_loader:\n", "        x = x.to(device, non_blocking=True)\n", "        loss = diffusion_loss(x)\n", "        opt.zero_grad(); loss.backward(); opt.step()\n", "        log.append(loss.item())\n", "    print(f\"[{ep:02d}/{epochs}] loss={np.mean(log[-len(train_loader):]):.4f} ({time.time()-t0:.1f}s)\")\n", "    if ep % sample_every == 0:\n", "        with torch.no_grad():\n", "            xg = p_sample_loop(64).cpu()\n", "            grid = vutils.make_grid(xg, nrow=8, normalize=True, value_range=(-1,1))\n", "        plt.figure(figsize=(6,6)); plt.axis(\"off\")\n", "        plt.title(f\"Generated samples @ epoch {ep}\")\n", "        plt.imshow(np.transpose(grid.numpy(), (1,2,0))); plt.show()\n", "        vutils.save_image(xg, os.path.join(out_dir, f\"samples_epoch_{ep:03d}.png\"),\n", "                          nrow=8, normalize=True, value_range=(-1,1))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 10) Loss curve"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["plt.figure(figsize=(6,3))\n", "plt.plot(log)\n", "plt.xlabel(\"training step\"); plt.ylabel(\"MSE (\u03b5-pred)\")\n", "plt.title(\"Diffusion training loss\"); plt.tight_layout(); plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 11) Notes\n", "- Linear beta schedule; try cosine for better quality.\n", "- Model predicts noise; predicting \\(x_0\\) or \\(v\\) are alternatives.\n", "- For faster sampling, try DDIM (drop noise, subsample steps)."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}